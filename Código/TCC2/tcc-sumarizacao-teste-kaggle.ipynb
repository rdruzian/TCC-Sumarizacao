{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\renat\\Anaconda3\\envs\\TCC\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\envs\\TCC\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\envs\\TCC\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\renat\\Anaconda3\\envs\\TCC\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\envs\\TCC\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\envs\\TCC\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\envs\\TCC\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\envs\\TCC\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from nltk import tokenize\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.models import Model\n",
    "import tensorflow_datasets as tfds\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib\n",
    "#import pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#nlp = pt_core_news_sm.load()\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('tcc1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = spacy.lang.pt.STOP_WORDS\n",
    "pontos = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frase_limpa(texto):\n",
    "    palavra = []\n",
    "    texto = texto.lower()\n",
    "    texto = nlp(texto)\n",
    "    for p in texto:\n",
    "        palavra.append(p.text)\n",
    "    texto = [p for p in palavra if p not in stopwords and p not in pontos]\n",
    "    texto = ' '.join([i for i in texto])\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticia_frase = []\n",
    "for i in range(len(data.texto)):\n",
    "    noticia_frase.append(frase_limpa(data.texto[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_frase = []\n",
    "for t in noticia_frase:\n",
    "    token_frase.append(t.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5037"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noticia_frase[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for t in token_frase:\n",
    "    for i in range(len(t)):\n",
    "        if len(t[i]) > 1:\n",
    "            tokens.append(t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78244"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = np.unique(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14819"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo_frase = []\n",
    "for i in range(len(data.título)):\n",
    "    titulo_frase.append(frase_limpa(data.título[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_t = []\n",
    "for t in titulo_frase:\n",
    "    token_t.append(t.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_titulos = []\n",
    "for t in token_t:\n",
    "    for i in range(len(t)):\n",
    "        if len(t[i]) > 0:\n",
    "            tokens_titulos.append(t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2451"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_titulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizador = tfds.features.text.SubwordTextEncoder.build_from_corpus(noticia_frase, target_vocab_size=2**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_input = [tokenizador.encode(frase) for frase in noticia_frase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(tokens)\n",
    "num_decoder_tokens = len(tokens_titulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokens:\n",
    "    token_frase = tokenizador.encode(i)\n",
    "for i in tokens_titulos:\n",
    "    token_titulo = tokenizador.encode(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\"abordagem', '\"bebês', '\"como', ..., '\\u200b\\u200bem', '”dias',\n",
       "       '”vídeo'], dtype='<U93')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(i, tokenizador.encode(i)) for i in tokens])\n",
    "target_token_index = dict([(i, tokenizador.encode(i)) for i in tokens_titulos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_max = max([len(frase)] for frase in frase_input)\n",
    "tam_max = tam_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_input = tf.keras.preprocessing.sequence.pad_sequences(frase_input, value = 0, padding='post', maxlen=tam_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo_input = [tokenizador.encode(titulo) for titulo in titulo_frase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo_max = max([len(titulo)] for titulo in titulo_input)\n",
    "titulo_max = titulo_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7069\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "print(tam_max)\n",
    "print(titulo_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo_input = tf.keras.preprocessing.sequence.pad_sequences(titulo_input, value = 0, padding='post', maxlen=titulo_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizador.vocab_size\n",
    "latent_dim = 128\n",
    "emb_dim = 25\n",
    "nb_filter = 25\n",
    "ffn_units = 128\n",
    "dropout_rate = 0.2\n",
    "nb_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 112. GiB for an array with shape (287, 7069, 14819) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3631a210d40e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m encoder_input_data = np.zeros(\n\u001b[0;32m      2\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrase_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtam_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_encoder_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     dtype='float32')\n\u001b[0m\u001b[0;32m      4\u001b[0m decoder_input_data = np.zeros(\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrase_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitulo_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_decoder_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 112. GiB for an array with shape (287, 7069, 14819) and data type float32"
     ]
    }
   ],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(frase_input), tam_max, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(frase_input), titulo_max, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(titulo_input), titulo_max, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(emb_dim, return_state=True)\n",
    "encoder_output, state_h, state_c = encoder(encoder_input)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "\n",
    "#encoder_input = Input(shape=(None,))\n",
    "#x = Embedding(vocab_size, latent_dim)(encoder_input)\n",
    "#x, state_h, state_c = LSTM(latent_dim, return_state=True)(x)\n",
    "#encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(emb_dim, return_sequences=True, return_state=True)\n",
    "decoder_output, _, _ = decoder_lstm(decoder_input, initial_state=encoder_state)\n",
    "decoder_dense = Dense(titulo_max, activation='softmax')\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "\n",
    "\n",
    "#decoder_inputs = Input(shape=(None,))\n",
    "#x = Embedding(vocab_size, latent_dim)(decoder_inputs)\n",
    "#x = LSTM(latent_dim, return_sequences=True)(x, initial_state=encoder_states)\n",
    "#decoder_outputs = Dense(vocab_size, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoder_lstm)\n",
    "print(decoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoder_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([encoder_input_data, decoder_target_data], batch_size=64, epochs=nb_epochs, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
