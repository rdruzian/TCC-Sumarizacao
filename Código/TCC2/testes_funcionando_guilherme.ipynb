{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiYHicaok-55",
    "outputId": "7f820bdc-f590-41a8-e697-c050cfec2e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from google.colab import drive\n",
    "drive.mount('/content/drive')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cCiShuJ2kJ46",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "C_WZdfH3vuAq"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1O-ULTskJ5D"
   },
   "source": [
    "# ETAPA DE CARREGAMENTO DO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SmMT4yLYkJ5E"
   },
   "outputs": [],
   "source": [
    "'''data = pd.read_json('/content/drive/My Drive/Colab Notebooks/tcc1.json', encoding='utf-8')'''\n",
    "data = pd.read_json('tcc1.json', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tgCi_w7kJ5H"
   },
   "source": [
    "# ETAPA DE PRÉ-PROCESSAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g0NmdK92kJ5H"
   },
   "outputs": [],
   "source": [
    "titulo_input = ['<start> ' + m + ' <end>' for m in data.título.tolist()]\n",
    "noticia_input = ['<start> ' + m + ' <end>' for m in data.texto.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX94W2FjkJ5K"
   },
   "source": [
    "# ETAPA DE TOKENIZAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R25m_iFJkJ5L"
   },
   "outputs": [],
   "source": [
    "def token(texto, tam_max):\n",
    "    tokens = tf.keras.preprocessing.text.Tokenizer(lower=True, filters='', num_words=2**16)\n",
    "    tokens.fit_on_texts(texto)\n",
    "    tensor = tokens.texts_to_sequences(texto)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=tam_max)\n",
    "    return tensor, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZMQ1BxRvkJ5N"
   },
   "outputs": [],
   "source": [
    "data_input_tokens, data_input = token(noticia_input, tam_max=600)\n",
    "data_target_tokens, target_input = token(titulo_input, tam_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GxtQBzu4kJ5Q"
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = data_input_tokens.shape[1]\n",
    "num_decoder_tokens = data_target_tokens.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQPcETPJkJ5T"
   },
   "source": [
    "# Divisão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rd9Tw4V5kJ5U",
    "outputId": "6654378e-1474-46f6-f549-f87709fb8b2d"
   },
   "outputs": [],
   "source": [
    "input_data_train, input_data_test, input_decoder_train, input_decoder_test = train_test_split(data_input_tokens, data_target_tokens, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1ihsvoJkJ5X"
   },
   "source": [
    "# Variáveis de configuração da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ksAX-lLEkJ5X"
   },
   "outputs": [],
   "source": [
    "buffer = len(input_data_train)\n",
    "batch = 16\n",
    "steps_por_epoca = len(input_data_train)//batch\n",
    "embedding_dim = 200\n",
    "units = 1024\n",
    "vocab_size_input = len(data_input.word_index)+1\n",
    "vocab_size_target = len(target_input.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_data_train, input_decoder_train)).shuffle(buffer)\n",
    "dataset = dataset.batch(batch, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dm3nCdlIkJ5a",
    "outputId": "81280187-41e0-4aeb-b8e3-575e30c3ab14"
   },
   "outputs": [],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lILhlbnSkJ5m"
   },
   "source": [
    "# Arquitetura da Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ifBysSYHkJ5m"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, emb_dim, units, batch):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch = batch\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "    def call(self, x, hidden):\n",
    "        print('x entrada encoder', x)\n",
    "        print('hidden entrada:', hidden)\n",
    "        x = self.embedding(x)\n",
    "        print('x encoder:', x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        print('output encoder:', output)\n",
    "        print('state encoder:', state)\n",
    "        return output, state\n",
    "    \n",
    "    def intializer_hidden_state(self):\n",
    "        return tf.zeros((self.batch, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCNz48DMkJ5p",
    "outputId": "e72dff37-903c-468b-b5b6-15acdd5f257a"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size_input, embedding_dim, units, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "asNtvs7zkJ5u"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rkEZu7eKkJ51"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, emb_dim, units, batch):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch = batch\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.units)\n",
    "\n",
    "    def call(self, x, hidden, output):\n",
    "        print('x decoder entrada:', x)\n",
    "        print('hidden decoder entrada:', hidden)\n",
    "        print('output decoder entrada:', output)\n",
    "        context_vector, attention_weights = self.attention(hidden, output)\n",
    "        x = self.embedding(x)\n",
    "        print('x decoder:', x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        print('output decoder:', output)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        return output, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRo90eCfkJ53",
    "outputId": "bc1170ba-a6a0-4c57-ef78-8e7e33d2494c"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size_target, embedding_dim, units, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zeZxJIh_kJ56"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "def erro(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    #print(mask.shape[0])\n",
    "    loss_ = loss_object(real, pred)\n",
    "    #print(loss_)\n",
    "    mask = tf.cast(mask.shape[0], dtype=loss_.dtype)\n",
    "    #print(type(mask))\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6crPZGaLkJ58"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './treinamento_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=tf.keras.optimizers.Adam(), encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "mQxRP3edkJ5_"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def treino(input_data, target, hidden):\n",
    "    loss = 0\n",
    "    batch = 16\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_output, encoder_hidden = encoder(input_data, hidden)\n",
    "        decoder_input = tf.expand_dims([target_input.word_index['<start>']] * batch, 1)\n",
    "\n",
    "        for t in range(1, target.shape[1]):\n",
    "            predictions, decoder_hidden, _ = decoder(decoder_input, encoder_hidden, encoder_output)\n",
    "            #print(type(predictions))\n",
    "            #print(target[:, t])\n",
    "            loss += erro(target[:, t], predictions)\n",
    "            #print(type(loss))\n",
    "            # using teacher forcing\n",
    "            decoder_input = tf.expand_dims(target[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(target.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "48MGJZS_kJ6C",
    "outputId": "965a6873-bd2a-4933-b009-da2618f53b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x entrada encoder Tensor(\"input_data:0\", shape=(16, 600), dtype=int32)\n",
      "hidden entrada: Tensor(\"hidden:0\", shape=(16, 1024), dtype=float32)\n",
      "x encoder: Tensor(\"encoder/embedding/embedding_lookup/Identity:0\", shape=(16, 600, 200), dtype=float32)\n",
      "output encoder: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "state encoder: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_1:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_1/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_1/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_2:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_2/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_2/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_3:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_3/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_3/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_4:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_4/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_4/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_5:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_5/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_5/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_6:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_6/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_6/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_7:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_7/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_7/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_8:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_8/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_8/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_9:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_9/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_9/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_10:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_10/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_10/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_11:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_11/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_11/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_12:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_12/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_12/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_13:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_13/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_13/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_14:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_14/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_14/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_15:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_15/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_15/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_16:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_16/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_16/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x decoder entrada: Tensor(\"ExpandDims_17:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_17/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_17/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_18:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_18/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_18/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x entrada encoder Tensor(\"input_data:0\", shape=(16, 600), dtype=int32)\n",
      "hidden entrada: Tensor(\"hidden:0\", shape=(16, 1024), dtype=float32)\n",
      "x encoder: Tensor(\"encoder/embedding/embedding_lookup/Identity:0\", shape=(16, 600, 200), dtype=float32)\n",
      "output encoder: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "state encoder: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_1:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_1/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_1/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_2:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_2/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_2/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_3:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_3/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_3/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_4:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_4/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_4/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_5:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_5/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_5/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_6:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_6/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_6/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_7:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_7/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_7/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_8:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_8/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_8/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_9:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_9/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_9/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_10:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_10/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_10/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_11:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_11/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_11/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_12:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_12/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_12/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_13:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_13/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_13/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_14:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_14/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_14/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x decoder entrada: Tensor(\"ExpandDims_15:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_15/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_15/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_16:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_16/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_16/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_17:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_17/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_17/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "x decoder entrada: Tensor(\"ExpandDims_18:0\", shape=(16, 1), dtype=int32)\n",
      "hidden decoder entrada: Tensor(\"encoder/gru/while:4\", shape=(16, 1024), dtype=float32)\n",
      "output decoder entrada: Tensor(\"encoder/gru/transpose_1:0\", shape=(16, 600, 1024), dtype=float32)\n",
      "x decoder: Tensor(\"decoder_18/embedding_1/embedding_lookup/Identity:0\", shape=(16, 1, 200), dtype=float32)\n",
      "output decoder: Tensor(\"decoder_18/gru_1/transpose_1:0\", shape=(16, 1, 1024), dtype=float32)\n",
      "Epoca 1 Erro nan\n",
      "Para uma época levou 39.5644s\n",
      "Epoca 2 Erro nan\n",
      "Para uma época levou 14.8606s\n",
      "Epoca 3 Erro nan\n",
      "Para uma época levou 14.9586s\n",
      "Epoca 4 Erro nan\n",
      "Para uma época levou 14.9691s\n",
      "Epoca 5 Erro nan\n",
      "Para uma época levou 14.9381s\n",
      "Epoca 6 Erro nan\n",
      "Para uma época levou 14.8296s\n",
      "Epoca 7 Erro nan\n",
      "Para uma época levou 14.8711s\n",
      "Epoca 8 Erro nan\n",
      "Para uma época levou 14.8421s\n",
      "Epoca 9 Erro nan\n",
      "Para uma época levou 14.8986s\n",
      "Epoca 10 Erro nan\n",
      "Para uma época levou 14.8191s\n",
      "Epoca 11 Erro nan\n",
      "Para uma época levou 14.5906s\n",
      "Epoca 12 Erro nan\n",
      "Para uma época levou 14.4265s\n",
      "Epoca 13 Erro nan\n",
      "Para uma época levou 14.6696s\n",
      "Epoca 14 Erro nan\n",
      "Para uma época levou 14.8481s\n",
      "Epoca 15 Erro nan\n",
      "Para uma época levou 14.9341s\n",
      "Epoca 16 Erro nan\n",
      "Para uma época levou 14.8781s\n",
      "Epoca 17 Erro nan\n",
      "Para uma época levou 14.8666s\n",
      "Epoca 18 Erro nan\n",
      "Para uma época levou 14.8746s\n",
      "Epoca 19 Erro nan\n",
      "Para uma época levou 14.8541s\n",
      "Epoca 20 Erro nan\n",
      "Para uma época levou 14.9096s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./treinamento_checkpoints\\\\ckpt-1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epocas = 20\n",
    "erro_acumulado = []\n",
    "for e in range(epocas):\n",
    "    inicio = time.time()\n",
    "    hidden = encoder.intializer_hidden_state()\n",
    "    erro_total = 0\n",
    "    for (batch, (input_data, target)) in enumerate(dataset.take(steps_por_epoca)):\n",
    "        batch_loss = treino(input_data, target, hidden)\n",
    "        erro_total += batch_loss\n",
    "    \n",
    "    print('Epoca {} Erro {:.04f}'.format(e+1, erro_total/steps_por_epoca))\n",
    "    erro_acumulado.append(erro_total/steps_por_epoca)\n",
    "    print('Para uma época levou {:.04f}s'.format(time.time() - inicio))\n",
    "checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "ogXHVeFTkJ6F",
    "outputId": "853584b2-4fa6-4848-8c7e-20c797e98e96"
   },
   "outputs": [],
   "source": [
    "#model = Model([encoder_inputs, decoder_inputs], decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hkTT2pV5kJ6I",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lzFyp5FkJ6K"
   },
   "source": [
    "# Compilação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6Itj6m-gkJ6L"
   },
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQyazX-QkJ6N"
   },
   "source": [
    "# Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FgqGqWfckJ6O"
   },
   "outputs": [],
   "source": [
    "#model.fit([encoder_input_data, decoder_input_data], decoder_input_data, batch_size=batch, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5zVjRIzjkJ6Q"
   },
   "outputs": [],
   "source": [
    "#model.save('sumAbstrat.h5')\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((num_encoder_tokens, num_decoder_tokens))\n",
    "    sentence = sentence.lower()\n",
    "    inputs = data_input.texts_to_sequences([sentence])\n",
    "    #inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=num_decoder_tokens, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([target_input.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(num_decoder_tokens):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        print(predictions)\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        print(predicted_id)\n",
    "        result += target_input.index_word[predicted_id] + ' '\n",
    "        if target_input.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-l-dA2oSvGmY"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>  Escutas telefônicas da operação que prendeu membros da Secretaria da Saúde mostram um homem que segundo o MP é integrante do esquema criminoso citando o governador do Rio. Quem menciona Wilson Witzel é o operador financeiro de Mário Peixoto, Luiz Roberto Martins. O governador nega que cometeu qualquer ilegalidade. Lava Jato prende ex-deputado Paulo Melo e empresário Mário Peixoto O operador diz a um interlocutor que o empresário negociou a liberação de uma organização social (OS) com o governador. A organização social Instituto Unir Saúde fechou vários contratos com a secretaria de saúde entre os anos de 2018 e 2019 até ser desqualificada como OS pelo estado em outubro de 2019.  Segundo as investigações da Operação Favorito, a OS movimentou mais de R$ 180 milhões em contratos de gestões de Upas na Baixada. Ainda de acordo com a Polícia Federal e o Ministério Público Federal, o empresário Mário Peixoto e seu operador financeiro Luiz Roberto Martins, ambos presos na semana passada, são os verdadeiros donos da OS e efetivamente promoveram negociação espúria com funcionários públicos estaduais. Supostas citações a Witzel em investigação que prendeu Mário Peixoto são enviadas à PGR Em ligação telefônica interceptada com autorização da Justiça no dia 20 de março deste ano, Luiz Roberto Martins anuncia a uma outra pessoa reclassificação da Unir. Segundo o operador financeiro de Mário Peixoto, o empresário teria acertado diretamente com o governador e que ele estaria comprando essa reclassificação de uma outra pessoa.  \"Diz o Mário que foi ele que acertou junto com o governador. Mas não publicou ainda. Eu estava comprando isso de um outro cara\", disse o operador para uma outra pessoa durante uma ligação.  Na conversa, Luiz Roberto Martins chegou a mostrar seu entusiasmo com o retorno da Unir para administração das Upas na Baixada.  \"As quatro de Nova Iguaçu não têm segundo colocado. Então está com contrato emergencial ainda. Se revogar e publicar a revogação tem que republicar o resultado do edital. Aí é nossa, p*. Mesquita, Queimados, Botafogo e Campos\", acrescentou o operador.  Para os investigadores, o grupo criminoso de Mário Peixoto pagou propina para funcionário público estadual ainda não identificado para obter o ato administrativo de revogação da desqualificação da OS, publicado no dia 23 de março.  Três dias depois do telefonema, a OS Instituto Unir Saúde foi reclassificado, podendo voltar a fechar contratos com o poder público. Segundo o MPF, a decisão não teve qualquer justificativa técnica.  Nesta segunda-feira (18), o jornal O Globo revelou que o governador Wilson Witzel ignorou pareceres jurídicos contra a OS Unir. Segundo a reportagem, em janeiro, a comissão de acompanhamento e fiscalização dos contratos de gestão da Secretaria da Casa Civil encontrou \"numerosas e consideráveis irregularidades na atuação da OS Unir, principalmente, em relação à transparência nas informações prestadas, que impossibilitam a análise da aplicação dos recursos obtidos.  Luiz Roberto Martins foi preso na última semana em sua casa, em Vassouras, no Sul do estado. No local, a Polícia Federal encontrou R$ 1,5 milhão em espécie. O que dizem os citados O governo do estado disse que todos os contratos celebrados com as empresas envolvidas nas denúncias estão sendo auditados pela Controladoria Geral do Estado, para verificar possíveis ilegalidades e danos aos cofres públicos.  O governo também informou que estão sendo feitos cruzamentos de contratos sociais das empresas para identificar conluios entre elas e os sócios, e que, enquanto durar a auditoria da controladoria, todos os pagamentos aos fornecedores fiscalizados estão suspensos e que esses contratos podem ser cancelados se forem encontradas irregularidades.  Ainda segundo o governo, Wilson Witzel desqualificou o Instituto Unir Saúde num despacho publicado em edição extra do diário oficial.  O advogado de Luiz Roberto Martins informou que só vai se manifestar depois de analisar todos os autos do processo.  <end>\n",
      "[[42, 7289, 4133, 8, 200, 5, 2770, 686, 8, 188, 8, 48, 549, 13, 761, 5, 39, 3, 1953, 16, 4134, 6, 870, 2505, 2506, 3, 284, 6, 873, 124, 4135, 983, 1242, 16, 3, 1350, 913, 1, 1081, 4136, 198, 718, 5281, 3, 284, 1536, 5, 7290, 265, 7291, 1535, 1672, 7292, 2773, 53, 3469, 4, 274, 1081, 2193, 3, 1350, 70, 2, 13, 7293, 5, 3, 274, 7294, 2, 1323, 1, 15, 324, 102, 7295, 10, 3, 1899, 2, 324, 102, 286, 1592, 48, 1058, 687, 664, 10, 2, 188, 1, 48, 56, 14, 90, 1, 1304, 4, 1465, 44, 41, 7296, 23, 14, 31, 58, 7, 1351, 1, 649, 39, 19, 2110, 8, 200, 7297, 2, 14, 5282, 20, 1, 77, 1752, 189, 7, 664, 1, 7298, 1, 1593, 12, 4137, 49, 1, 86, 10, 2, 130, 107, 4, 3, 93, 157, 514, 3, 274, 1081, 2193, 4, 78, 1350, 913, 198, 718, 2933, 1166, 852, 12, 131, 826, 26, 14, 7299, 3470, 8, 14, 4, 5283, 7300, 2194, 7301, 10, 420, 1082, 5284, 5285, 7302, 2, 1242, 7, 463, 5, 2770, 1081, 2193, 26, 5286, 29, 7303, 7, 2388, 5287, 7304, 10, 1748, 8, 391, 11, 61, 360, 1, 630, 233, 553, 198, 718, 1142, 2366, 2, 15, 237, 335, 4138, 8, 4139, 39, 3, 1350, 913, 1, 1081, 4136, 3, 274, 323, 7305, 1191, 10, 3, 284, 4, 5, 40, 4140, 2507, 88, 4138, 1, 15, 237, 4141, 7306, 3, 1081, 5, 21, 40, 5, 7307, 803, 10, 3, 1899, 32, 17, 2191, 2360, 28, 137, 2507, 74, 1, 13, 326, 7308, 50, 3, 1350, 9, 15, 237, 335, 65, 15, 7309, 12, 5288, 198, 718, 1142, 183, 2, 2508, 78, 4142, 10, 3, 476, 8, 1592, 9, 1014, 30, 1593, 12, 4137, 1466, 314, 1, 234, 2195, 17, 170, 39, 7310, 179, 46, 10, 1467, 459, 2360, 25, 7311, 4, 5289, 2, 4143, 38, 5, 7312, 3, 422, 6, 7313, 675, 16, 1954, 7314, 7315, 7316, 4144, 4, 7317, 928, 3, 7318, 9, 14, 7319, 3, 166, 2505, 1, 1081, 2193, 5290, 7320, 9, 1243, 157, 204, 49, 17, 1541, 9, 1120, 3, 2196, 4145, 1, 4143, 8, 7321, 8, 7322, 1753, 11, 61, 1151, 1, 764, 159, 97, 126, 6, 7323, 2, 14, 286, 1592, 48, 21, 7324, 4146, 1232, 2, 1955, 664, 10, 3, 256, 969, 39, 3, 7325, 2, 313, 17, 176, 265, 7326, 7327, 47, 66, 253, 3, 559, 3, 1009, 2173, 5, 3, 284, 983, 1242, 7328, 3954, 7329, 87, 2, 14, 4139, 39, 2, 3471, 7, 434, 2, 2197, 1, 1037, 4, 1456, 22, 664, 1, 306, 8, 188, 8, 169, 489, 2509, 7330, 4, 7331, 1594, 12, 1698, 8, 14, 7332, 2934, 7, 195, 29, 1693, 51, 258, 7333, 5, 7334, 2, 1015, 8, 807, 22, 244, 7335, 198, 718, 1142, 21, 3472, 12, 341, 131, 7, 67, 513, 7, 7336, 11, 300, 6, 674, 11, 944, 2, 130, 107, 2509, 77, 1160, 610, 7, 7337, 3, 5, 982, 14, 3295, 3, 63, 6, 58, 50, 5, 111, 14, 664, 7338, 10, 19, 371, 4147, 51, 1119, 68, 146, 7339, 35, 2935, 709, 6, 711, 9, 1209, 1468, 7340, 4, 2923, 96, 4148, 2936, 3, 63, 33, 231, 5, 68, 146, 988, 4149, 1, 664, 490, 30, 371, 9, 609, 7341, 56, 480, 4, 14, 7342, 4, 110, 181, 5291, 2, 5292, 8, 7343, 111, 14, 2937, 96, 3473, 7344, 68, 7345, 4, 5, 304, 664, 190, 41, 7346, 25, 1407, 5293, 5294, 49, 39, 3, 636, 983, 1242, 7347, 3, 286, 1592, 48, 744, 5295, 1753, 7, 1220, 4150, 6, 1066, 3474, 3, 406, 1, 198, 718, 1142, 231, 5, 108, 85, 25, 2474, 126, 1, 2510, 111, 14, 5296, 6, 2511, 43]]\n",
      "(1, 20)\n",
      "(1, 20)\n",
      "x entrada encoder tf.Tensor(\n",
      "[[ 406    1  198  718 1142  231    5  108   85   25 2474  126    1 2510\n",
      "   111   14 5296    6 2511   43]], shape=(1, 20), dtype=int32)\n",
      "hidden entrada: [<tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>]\n",
      "x encoder: tf.Tensor(\n",
      "[[[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]], shape=(1, 20, 200), dtype=float32)\n",
      "output encoder: tf.Tensor(\n",
      "[[[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]], shape=(1, 20, 1024), dtype=float32)\n",
      "state encoder: tf.Tensor([[nan nan nan ... nan nan nan]], shape=(1, 1024), dtype=float32)\n",
      "x decoder entrada: tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
      "hidden decoder entrada: tf.Tensor([[nan nan nan ... nan nan nan]], shape=(1, 1024), dtype=float32)\n",
      "output decoder entrada: tf.Tensor(\n",
      "[[[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [nan nan nan ... nan nan nan]]], shape=(1, 20, 1024), dtype=float32)\n",
      "x decoder: tf.Tensor(\n",
      "[[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "   nan nan nan nan nan nan nan nan nan nan nan nan nan]]], shape=(1, 1, 200), dtype=float32)\n",
      "output decoder: tf.Tensor([[[nan nan nan ... nan nan nan]]], shape=(1, 1, 1024), dtype=float32)\n",
      "tf.Tensor([[nan nan nan ... nan nan nan]], shape=(1, 1024), dtype=float32)\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-59c176895537>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmensagem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmensagem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-c5a87b4b04cb>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted translation: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-19fccd02dcf4>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mpredicted_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtarget_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarget_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'<end>'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "mensagem = '<start> ' + data.texto.tolist()[15] + ' <end>'\n",
    "print(mensagem)\n",
    "\n",
    "translate(mensagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "testes_funcionando.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
