{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J8EJ1hqdVEJ"
   },
   "source": [
    "Importação das bibliotecas que serão utilizadas para a criação do algoritmo de Sumarização Abstrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ebbZQqKZdVEK",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "import tensorflow_datasets as tfds\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Amk2yS2Rl9Wu"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang, max_seq):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=True, filters='',\n",
    "                                                         num_words=2**16)\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post',\n",
    "                                                         maxlen=max_seq)\n",
    "\n",
    "  return tensor, lang_tokenizer\n",
    "\n",
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRgMGI5pdVEN"
   },
   "source": [
    "Carregado o dataset com as notícias, separando o texto e o título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KbfDZKwMdVEN"
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('tcc1.json', encoding='utf-8')\n",
    "\n",
    "noticias = ['<start> ' + m + ' <end>' for m in data.texto.tolist()]\n",
    "titulos  = ['<start> ' + m + ' <end>' for m in data.título.tolist()]\n",
    "\n",
    "input_tensor, inp_lang = tokenize(noticias, max_seq=600)\n",
    "target_tensor, targ_lang = tokenize(titulos, max_seq=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> Falta de política clara para conter pandemia atrasa retomada da economia, dizem empresários  <end>',\n",
       " '<start> Brasil chega a 16.792 mortes e se torna 3º do mundo com mais casos <end>',\n",
       " '<start> MPF investigará se Flávio Bolsonaro foi avisado de operação da PF <end>',\n",
       " \"<start> Advogado investigado por 'rachadinha' é suspeito de presenciar suposto vazamento <end>\",\n",
       " '<start> Celso de Mello diz que decidirá sobre sigilo do vídeo até o fim da semana <end>',\n",
       " \"<start> Empresa anuncia resultados 'positivos preliminares' em teste de vacina <end>\",\n",
       " \"<start> Vereadores aprovam 'feriadão' em SP para tentar aumentar isolamento <end>\",\n",
       " '<start> Hospital de referência em Natal fecha as portas do PS <end>',\n",
       " '<start> Nem novos leitos dão conta do avanço do coronavírus no Ceará <end>',\n",
       " '<start> Maranhão planeja reabertura na próxima semana, diz governador <end>',\n",
       " \"<start> Enfermeiros e médicos do RJ mostram rotina: '6 horas sem beber água' <end>\",\n",
       " '<start> Governador de Pernambuco testa positivo para Covid-19  <end>',\n",
       " '<start> Desmatamento da Amazônia em abril foi o maior em 10 anos, diz instituto <end>',\n",
       " '<start> Por que a Espanha mostra que deveremos ter mais quarentenas <end>',\n",
       " \"<start> 'Novo normal': Europa retoma atividades com cuidados extras <end>\",\n",
       " '<start> Operador de empresário preso cita negociação com Witzel, mostra escuta  <end>',\n",
       " '<start> Governo começa a pagar hoje 2ª parcela do auxílio de R$ 600 <end>',\n",
       " '<start> Pequenas empresas: vale a pena pegar crédito para salários? <end>',\n",
       " '<start> Planalto manda Weintraub entregar ao Centrão fundo bilionário <end>',\n",
       " '<start> Defensoria Pública entra com recurso para adiar o Enem <end>',\n",
       " \"<start> Nº de mortes em SP mostra tendência de 'pico contínuo'; entenda <end>\",\n",
       " '<start> Apoiadores de Bolsonaro detidos por desobediência vão para presídio <end>',\n",
       " '<start> Trump diz que toma remédio de eficácia não comprovada para prevenir a Covid <end>',\n",
       " '<start> Para onde vai o dinheiro arrecadado nas lives da quarentena? <end>',\n",
       " '<start> Obra de Ian Curtis, morto há 40 anos, infelizmente nunca foi tão atual <end>',\n",
       " '<start> Giulia Be se solta em 1º disco após virar hit em Portugal <end>',\n",
       " '<start> Toffoli libera aplicação de MP que reduz contribuições ao Sistema S <end>',\n",
       " '<start> Recesso parlamentar é cancelado em meio à pandemia <end>',\n",
       " '<start> Bovespa fecha em forte alta e passa dos 81 mil pontos <end>',\n",
       " '<start> GM e Volkswagen retomam produção de veículos no Brasil <end>',\n",
       " '<start> 30 anos depois, Collor pede desculpas por confisco da poupança <end>',\n",
       " '<start> É #FAKE que ministério repasse R$ 12 mil a hospitais por cada morte por Covid <end>',\n",
       " '<start> Bahia prorroga suspensão de aulas e eventos até 2 de junho <end>',\n",
       " '<start> Niterói vai liberar parte do comércio e acesso à orla na quinta <end>',\n",
       " '<start> Moradores de Paraisópolis cobram ações do governo de SP <end>',\n",
       " '<start> Belo Horizonte inicia barreiras sanitárias na entrada da cidade <end>',\n",
       " '<start> Empresas doam eletrodomésticos e criam fundo para motoristas de aplicativo <end>',\n",
       " \"<start> 'Lavo as mãos a ponto de feri-las': as pessoas com TOC na pandemia <end>\",\n",
       " '<start> Instagram lança nova ferramenta para ajudar na pandemia <end>',\n",
       " '<start> Pai faz cerimônia de formatura para filha na frente de casa nos EUA <end>',\n",
       " '<start> Policiais e manifestantes entram em confronto em Santiago <end>',\n",
       " \"<start> Trans viram alvo no Panamá após 'lockdown por gênero' <end>\",\n",
       " '<start> Deputado federal Luiz Lauro Filho morre após infarto em SP <end>',\n",
       " '<start> Homem mostra arma, bíblia e Constituição e se nega a pôr máscara no DF <end>',\n",
       " '<start> Por que tem gente que age como se não houvesse a pandemia? <end>',\n",
       " '<start> Drauzio Varella explica por que mortes entre obesos são mais comuns <end>',\n",
       " '<start> Voluntários ajudam idosos a enfrentar isolamento com festinhas e shows virtuais <end>',\n",
       " '<start> Doação do cofrinho, cartas, desenhos: como crianças enfrentam a pandemia <end>',\n",
       " '<start> Experimento mostra como máscara e distanciamento são importantes <end>',\n",
       " '<start> Cientistas brasileiros reproduzem em 3D bactérias de 2 bilhões de anos <end>',\n",
       " '<start> Ex-vereador do Rio Jorginho da SOS morre após contrair Covid-19 <end>',\n",
       " '<start> Meryl Streep e Benedict Cumberbatch leem livro online para iniciativa de caridade <end>',\n",
       " '<start> Polícia da Austrália prende adolescente alemão por roubo e selfies em museu <end>',\n",
       " \"<start> Advogado investigado no caso das 'rachadinhas' é suspeito de \\npresenciar vazamento de operação <end>\",\n",
       " '<start> Policiais do Chile e manifestantes entram em confronto em Santiago; bairro enfrenta escassez de alimentos <end>',\n",
       " '<start> Lucro operacional da Marfrig mais que dobra no 1º trimestre <end>',\n",
       " '<start> Fafá de Belém anuncia sua primeira live para 13 de junho só com temas românticos de novelas <end>',\n",
       " '<start> Isolamento social funciona de diferentes formas no Rio e em outros municípios do RJ  <end>',\n",
       " '<start> Protesto de caminhoneiros provoca congestionamento na Marginal Tietê no 1º dia sem rodízio ampliado em SP <end>',\n",
       " '<start> Material volta a ser entregue em obras para instalar tomógrafo em terreno de igreja na Rocinha <end>',\n",
       " '<start> Escuta telefônica mostra operador de Mário Peixoto citando suposta negociação entre o empresário e Wilson Witzel   <end>',\n",
       " '<start> Gilmar Mendes concede prisão domiciliar a acusada de homicídio que deu à luz na prisão <end>',\n",
       " '<start> MPF vai apurar novas denúncias de vazamento da PF na Operação Furna da Onça <end>',\n",
       " '<start> Falta de coordenação no combate ao coronavírus prejudica retomada da economia, apontam empresários <end>',\n",
       " '<start> Cerca de 12 mil alunos da rede municipal de SP não receberam as apostilas das aulas à distância <end>',\n",
       " '<start> Idosa de 90 anos deixa hospital no RJ após se recuperar da Covid-19 <end>',\n",
       " '<start> Segurança de mercado preso por chicotear jovem em SP vai a regime semiaberto cinco meses após condenação <end>',\n",
       " '<start> Nora de Crivella é sócia de um dos presos por suspeita de fraude na Saúde do RJ <end>',\n",
       " '<start> Apoiadores de Bolsonaro que fizeram ato contra Alexandre de Moraes são transferidos para presídio em SP <end>',\n",
       " '<start> Justiça derruba lei que autorizava Guarulhos a remanejar R$ 1 bilhão sob pretexto do coronavírus <end>',\n",
       " '<start> Prefeitura do Rio abre novos postos de vacinação contra a gripe em sistema drive thru nesta terça-feira <end>',\n",
       " '<start> Lojas Renner diz ter vencido ação tributária de R$ 1,36 bilhão <end>',\n",
       " '<start> Bolsas de Nova York sobem com avanço em vacina, reabertura e Powell <end>',\n",
       " '<start> Israelenses inventam máscara para alimentação em restaurantes durante pandemia de Covid-19 <end>',\n",
       " '<start> Brasil passa o Reino Unido ao bater mais de 250 mil casos confirmados de Covid-19; total de mortes vai a 16.792 <end>',\n",
       " '<start> É #FAKE que Ministério da Saúde repassa R$ 12 mil a hospitais por cada morte por Covid-19 <end>',\n",
       " '<start> Ex-presidente Collor pede desculpas por confisco da poupança <end>',\n",
       " '<start> Perdas do RJ em ICMS podem ser revisadas para R$ 7 bilhões, diz secretário de Fazenda  <end>',\n",
       " '<start> Em 4 semanas, mortes de pretos e pardos por Covid-19 passam de 32,8% para 54,8% <end>',\n",
       " '<start> Empresa dos EUA diz que encontrou anticorpo que impede infecção pelo novo coronavírus, mas não apresenta prova <end>',\n",
       " '<start> Trump diz estar tomando remédio de eficiência não comprovada como prevenção ao coronavírus <end>',\n",
       " '<start> Cidade de SP recebe 20 respiradores do Ministério da Saúde; equipamentos vão para três hospitais com UTIs lotadas <end>',\n",
       " '<start> Instagram lança nova ferramenta para agregar conteúdo; Brasil é um dos primeiros a receber <end>',\n",
       " '<start> Consórcio Intermunicipal do ABC espera decisão do governo de SP sobre lockdown <end>',\n",
       " '<start> TRF-3 rejeita denúncia contra Lula por suposto pagamento de mesada da Odebrecht <end>',\n",
       " '<start> Comitê para fiscalizar hospitais de campanha começa a funcionar no RJ <end>',\n",
       " \"<start> Uso da cloroquina contra Covid-19 é 'perigoso', 'carece de evidência' e tomou aspecto político inesperado, diz Sociedade de Imunologia <end>\",\n",
       " '<start> Vestibular 2020.2 da Ibmec Rio está com inscrições abertas  <end>',\n",
       " '<start> Celso de Mello decide sobre sigilo da gravação de reunião ministerial até o fim da semana, informa STF <end>',\n",
       " '<start> Parque de animais marinhos celebra nascimento de sua 2ª geração de golfinhos na França <end>',\n",
       " '<start> RJ tem número recorde de 4.427 casos de Covid-19 confirmados em 24 horas; total chega a 26.665 <end>',\n",
       " '<start> Preços do petróleo saltam com alívio de lockdown e resultado positivo para vacina <end>',\n",
       " '<start> É #FAKE que vídeo mostre presos sem máscara em fila para receber auxílio em banco no meio da pandemia <end>',\n",
       " '<start> PIB recuou 1% no primeiro trimestre, aponta monitor da FGV <end>',\n",
       " \"<start> Violência doméstica: 'Fui estuprado pela minha mulher por 10 anos' <end>\",\n",
       " '<start> Câmara de SP aprova antecipação de feriados municipais para aumentar isolamento social <end>',\n",
       " '<start> Hacking.Rio promove hackathon online para desenvolver soluções de combate à Covid-19 <end>',\n",
       " \"<start> 6ix9ine diz que liderança de Ariana Grande e Justin Bieber na parada da 'Billboard' foi comprada <end>\",\n",
       " '<start> Sargento do Corpo de Bombeiros do RJ morre de Covid-19, diz corporação <end>',\n",
       " \"<start> Harry Styles lança clipe de 'Watermelon sugar', gravado antes da quarentena; assista <end>\",\n",
       " '<start> Niterói voltará a liberar parte do comércio e acesso à orla, de forma gradual, na quinta-feira <end>',\n",
       " '<start> Enem 2020: Defensoria Pública entra com recurso para adiar prova <end>',\n",
       " '<start> Ex-secretário de Saúde do RJ, Edmar Santos diz que não sabia que iria seguir na pasta   <end>',\n",
       " '<start> Testes de Covid-19 aplicados pelo Ibope em moradores de Uberaba dão negativo <end>',\n",
       " '<start> Uber demite mais 3 mil funcionários em segundo corte este mês <end>',\n",
       " '<start> Veja as fotos selecionadas no RJ pelo #ExpedicaoGloboDaJanela <end>',\n",
       " '<start> Antes do coronavírus: a esquecida gripe de Hong Kong, epidemia que matou mais de 1 milhão há 5 décadas <end>',\n",
       " '<start> Prefeitura do Rio diz que houve aumento na taxa de isolamento em vários bairros da cidade no domingo <end>',\n",
       " '<start> Toffoli suspende decisão que impedia aplicação de MP que reduz contribuições ao Sistema S <end>',\n",
       " '<start> Educação Financeira #89: Pequenas empresas - vale a pena ou não pegar crédito para salários e capital de giro? Veja dicas <end>',\n",
       " '<start> É #FAKE que juiz Marcelo Bretas fez post defendendo uso de remédio experimental e falando em hospitais de campanha superfaturados  <end>',\n",
       " '<start> Coronavírus: por que o exemplo da Espanha mostra que mundo precisará de novas quarentenas <end>',\n",
       " \"<start> Coronavírus: o sofrimento da comunidade trans com o 'lockdown por gênero' no Panamá <end>\",\n",
       " '<start> Balança comercial tem superávit de US$ 3,67 bilhões na parcial de maio <end>',\n",
       " '<start> Pais argentinos e filho recém-nascido, separados por 13 mil km devido ao coronavírus <end>',\n",
       " '<start> Governo lança site para devolução de auxílio emergencial recebido de forma indevida <end>',\n",
       " '<start> Frigorífico em Ipumirim é interditado por irregularidades na prevenção ao novo coronavírus <end>',\n",
       " '<start> Congresso cancela recesso parlamentar de meio do ano devido à crise do coronavírus <end>',\n",
       " '<start> Médicos e enfermeiros mostram a rotina em CTI de Covid-19 no RJ; equipe fica até 6 horas sem água <end>',\n",
       " \"<start> AGU diz à Justiça que fotos de Bolsonaro em posts do Planalto não são 'promoção pessoal' <end>\",\n",
       " '<start> Camex zera imposto de importação de mais 118 produtos para combate ao coronavírus <end>',\n",
       " '<start> Bolsas da Europa fecham em alta com otimismo sobre o controle da pandemia <end>',\n",
       " '<start> PM reforça patrulhamento no entorno da casa de Paulo Marinho após pedido do empresário <end>',\n",
       " \"<start> Data do Enem 2020 'não é imutável', diz Inep  <end>\",\n",
       " \"<start> Presidente do SoftBank afirma que foi 'tolo' ao investir no WeWork  <end>\",\n",
       " \"<start> Moody's alerta para riscos a perspectiva estável da nota do Brasil diante de recessão profunda <end>\",\n",
       " '<start> Morre deputado federal Luiz Lauro Filho aos 41 anos em Campinas <end>',\n",
       " '<start> SP imuniza 14% das crianças menores de 6 anos contra gripe; meta é de 95% <end>',\n",
       " '<start> Imagens mostram rato, baratas e pombos no único hospital de Itaguaí, RJ  <end>',\n",
       " '<start> Lucky Peterson, guitarrista de blues, morre aos 55 anos nos EUA <end>',\n",
       " '<start> É #FAKE que vídeos mostrem pessoas se passando por agentes de saúde para contaminar a população <end>',\n",
       " '<start> Morre Laudo Natel, ex-governador de SP, aos 99 anos <end>',\n",
       " '<start> Espaço de isolamento para casos leves de Covid-19 no Jardim Ângela, na Zona Sul de SP, começa a receber pacientes nesta segunda <end>',\n",
       " \"<start> Bolsonaro provoca 'caos na saúde e semeia a morte', diz editorial do jornal francês 'Le Monde' <end>\",\n",
       " '<start> Ainda em obras, hospital de campanha de São Gonçalo deve ser inaugurado na quinta-feira  <end>',\n",
       " '<start> 2 em cada 10 pais de alunos não conseguiram pagar mensalidade de abril das escolas particulares em SP, diz sindicato <end>',\n",
       " '<start> Presidente de El Salvador polemiza ao declarar emergência sem consultar Congresso <end>',\n",
       " '<start> SP deve ter feriadão de 6 dias a partir de quarta (20) para aumentar isolamento <end>',\n",
       " '<start> Ex-chefe da comunicação da PF volta ao posto após ocupar cargos em secretarias da Presidência da República <end>',\n",
       " '<start> SP chega a 4.823 mortes por Covid-19 e 63.066 casos confirmados da doença <end>',\n",
       " '<start> Com 20 mortes por Covid, hospital de campanha do Anhembi é administrado por organização investigada por irregularidades <end>',\n",
       " '<start> Defensoria Pública do RJ entra na Justiça para cobrar distribuição de cestas básicas aos alunos da rede pública de Educação <end>',\n",
       " '<start> Pai surpreende filha com cerimônia de formatura diante de casa nos EUA <end>',\n",
       " '<start> Taxa de isolamento sobe para 54% no estado de SP no domingo; na capital paulista chega a 56% <end>',\n",
       " '<start> Petrobras reajusta preço do diesel nas refinarias em 8% <end>',\n",
       " '<start> Comerciantes da Rocinha protestam contra remoção de boxes para acesso a tomógrafo em templo da Universal <end>',\n",
       " '<start> Em assembleia da OMS, ministro interino da Saúde defende articulação do governo federal com Estados e municípios no combate ao coronavírus <end>',\n",
       " '<start> Bolsonaro quer aval de governadores para veto a reajuste de servidores <end>',\n",
       " '<start> Governo de SP começa a testar casos leves de coronavírus por RT-PCR nesta segunda <end>',\n",
       " '<start> Polícia do RJ identifica 12 mortos em operação no Alemão e investiga os casos <end>',\n",
       " \"<start> Huawei diz que decisão dos EUA de restringir  fornecimento de chips é 'arbitrária' <end>\",\n",
       " '<start> Economia do Chile cresce 0,4% no 1º trimestre, diz BC local <end>',\n",
       " '<start> Chefe do FMI adverte que recuperação econômica global completa é improvável em 2021 <end>',\n",
       " '<start> UFF cria respirador para tratamento de pacientes com Covid-19 no RJ <end>',\n",
       " '<start> SP registra 3 km de trânsito após retomada do rodízio tradicional na cidade <end>',\n",
       " '<start> Xi Jinping promete vacina e US$ 2 bilhões contra o coronavírus <end>',\n",
       " '<start> Teste em humanos de vacina contra coronavírus tem resultados positivos preliminares, diz empresa <end>',\n",
       " \"<start> Paulo Marinho diz ter 'elementos que comprovam' relato sobre suposto vazamento da PF a Flávio <end>\",\n",
       " '<start> Vendas reais no varejo brasileiro despencam 36,5% em abril, aponta indicador <end>',\n",
       " '<start> Michel Piccoli, lendário ator francês, morre aos 94 anos <end>',\n",
       " '<start> Lives de hoje: Jon Bon Jovi e Whindersson Nunes e mais shows para ver em casa <end>',\n",
       " '<start> Planalto manda Weintraub entregar comando do fundo bilionário ao centrão nos próximos dias <end>',\n",
       " '<start> GM e Volkswagen retomam produção de veículos no Brasil <end>',\n",
       " '<start> Moradores de Paraisópolis protestam por medidas contra o coronavírus nas favelas <end>',\n",
       " '<start> Bovespa fecha em forte alta e passa dos 81 mil pontos <end>',\n",
       " '<start> Cidades da região oferecem 55 vagas de emprego nesta segunda-feira; veja lista <end>',\n",
       " \"<start> Investigação sobre resposta à pandemia será lançada 'em momento apropriado', diz chefe da OMS <end>\",\n",
       " '<start> Estratégia do Planalto é escolher novo ministro da Saúde após general assinar mudança no protocolo da cloroquina  <end>',\n",
       " '<start> Pagamento da segunda parcela do auxílio emergencial causa filas extensas no Grande Recife <end>',\n",
       " '<start> 24 municípios de SP apresentam tendência de piora na epidemia por Covid-19, aponta levantamento <end>',\n",
       " '<start> Lives da semana: Gusttavo Lima, Pabllo Vittar, Ferrugem, Simone & Simaria, Alcione e mais shows <end>',\n",
       " '<start> Na mira de investigação, Bolsonaro muda tom para não atrapalhar negociação com o Centrão <end>',\n",
       " '<start> Governo nomeia indicado do PL para diretoria do Fundo Nacional de Desenvolvimento da Educação  <end>',\n",
       " '<start> Dólar fecha em queda e se aproxima de R$ 5,70 <end>',\n",
       " '<start> Subnotificação em favelas tende a ‘reduzir a percepção de risco’, alerta médico da Uerj sobre coronavírus <end>',\n",
       " '<start> Mais de 150 médicos cubanos são aprovados para o programa Mais Médicos para o Brasil <end>',\n",
       " '<start> Governo suspende atualização do cadastro de beneficiários do Bolsa Família  <end>',\n",
       " '<start> China recomenda que empresas de alimentos elevem estoques por medo de surto da Covid-19 no Brasil <end>',\n",
       " \"<start> Chefe da ONU diz que mundo paga 'preço alto' por estratégias divergentes no combate à pandemia <end>\",\n",
       " '<start> Analistas do mercado financeiro passam a estimar tombo de 5,12% para o PIB em 2020  <end>',\n",
       " \"<start> Cantor Sorocaba anuncia nascimento do primeiro filho: 'Maior experiência da minha vida' <end>\",\n",
       " '<start> Varas da Infância no RJ atendem de forma remota a casos de adoção e dão uma nova família a crianças em abrigos <end>',\n",
       " '<start> Prefeitura do Rio anuncia compra emergencial de caminhões frigoríficos para hospitais <end>',\n",
       " '<start> Mercados de ações e petróleo saltam à medida que economias reabrem <end>',\n",
       " '<start> Apesar de proibição, ônibus no Rio ainda circulam com gente em pé; sindicato afirma que 25 rodoviários já morreram de Covid-19 <end>',\n",
       " '<start> Bolsas asiáticas fecham em alta nesta segunda-feira <end>',\n",
       " '<start> Famílias denunciam falta de informação sobre parentes internados em hospitais do RJ <end>',\n",
       " '<start> Japão entra em recessão e caminha para pior contração pós-guerra <end>',\n",
       " '<start> Novo secretário de Saúde do RJ diz que vai dar prioridade a leitos de enfermaria para reduzir a demanda de UTI <end>',\n",
       " '<start> O caminho das doações: O que é feito com o dinheiro arrecadado em lives da quarentena <end>',\n",
       " \"<start> Desempregados, familiares de presos: os excluídos 'por engano' do Auxílio Emergencial de R$ 600 <end>\",\n",
       " '<start> Iza lança single humanitário com o rapper norte-americano Maejor <end>',\n",
       " '<start> Ian Curtis: 40 anos depois, obra do cantor do Joy Division é infelizmente mais apropriada do que nunca <end>',\n",
       " '<start> O risco da falsa segurança <end>',\n",
       " '<start> Detran-RJ retoma agendamentos para emissão de RG <end>',\n",
       " '<start> Polícia Militar faz operação no Morro do Vidigal, no Rio; Av. Niemeyer chegou a ser interditada  <end>',\n",
       " '<start> Casos de coronavírus e número de mortes no Brasil em 18 de maio <end>',\n",
       " '<start> Casos de coronavírus e número de mortes no Brasil em 18 de maio <end>',\n",
       " '<start> Termina nesta segunda-feira esquema de bloqueios em bairros do Rio <end>',\n",
       " '<start> Beneficiários do auxílio emergencial devem agendar para emitir carteira de identidade na quarentena <end>',\n",
       " '<start> Últimas notícias de coronavírus de 18 de maio <end>',\n",
       " '<start> País tem mais de 100 concursos públicos abertos para 15 mil vagas <end>',\n",
       " '<start> Giulia Be se solta em 1º disco, após virar hit em Portugal, cantando pop com colagens de sons <end>',\n",
       " '<start> Cientistas brasileiros produzem imagens em 3D de formas de vida de 1,9 bilhão de anos atrás; VÍDEO <end>',\n",
       " '<start> Polícia Civil do RJ tem déficit histórico de 15 mil agentes e 25% já podem se aposentar <end>',\n",
       " \"<start> WC no Beat ostenta Ludmilla, Vitão, Anitta e Karol Conka no álbum 'Griff' <end>\",\n",
       " \"<start> Cientistas alertam para aumento nas mortes por Covid-19 em SP nos últimos dias e possibilidade de pico de mortes virar 'platô' <end>\",\n",
       " '<start> Portugal tem volta às aulas parcial nesta segunda-feira, com medidas de proteção e distanciamento <end>',\n",
       " \"<start> 83% dos principais países afetados pelo coronavírus adotaram 'lockdown', aponta levantamento <end>\",\n",
       " '<start> Rodízio de carros tradicional volta a vigorar nesta segunda em São Paulo; veja placas que podem circular <end>',\n",
       " '<start> Vaticano reabre a Basílica de São Pedro após mais de dois meses fechada ao público <end>',\n",
       " '<start> Auxílio Emergencial: governo começa a pagar a segunda parcela do benefício <end>',\n",
       " \"<start> Wesley Safadão põe 'Blefe' entre as músicas inéditas de álbum gravado ao vivo em live <end>\",\n",
       " \"<start> Discos para descobrir em casa – 'Chama acesa', Ivan Lins, 1975 <end>\",\n",
       " '<start> PGR pede para Polícia Federal ouvir Paulo Marinho em inquérito sobre Bolsonaro <end>',\n",
       " '<start> Balão cai e atinge rede elétrica sobre trem da CPTM na Grande SP <end>',\n",
       " '<start> Avião militar canadense cai durante acrobacia para entreter confinados <end>',\n",
       " '<start> Brasil tem 16.118 mortes e 241.080 casos confirmados de novo coronavírus, diz ministério <end>',\n",
       " '<start> Botucatu registra sétima morte por Covid-19; paciente tinha 59 anos  <end>',\n",
       " '<start> Presidente e rival assinam acordo de divisão de poder no Afeganistão <end>',\n",
       " '<start> Diretor-geral do Hospital Gaffrée e Guinle, Fernando Ferry será o novo secretário de Estado de Saúde do RJ <end>',\n",
       " '<start> RJ tem mais de 22 mil casos de Covid-19, com 2.715 mortes e 17,5 mil recuperados da doença <end>',\n",
       " '<start> Mais de mil pessoas morreram por coronavírus em 1 semana em SP; taxa de ocupação de UTIs na Grande SP vai a 92% <end>',\n",
       " '<start> Calor na Europa e primavera nos EUA testam novas regras contra o novo coronavírus <end>',\n",
       " '<start> Merkel destaca importância da imprensa crítica em tempos de pandemia <end>',\n",
       " '<start> Prefeitura do Rio promove ato simbólico pelo Dia Internacional de Combate à LGBTfobia <end>',\n",
       " '<start> Ex-ministros da Defesa reafirmam em nota compromisso das Forças Armadas com a democracia <end>',\n",
       " '<start> Cinco potenciais crises internacionais para além da pandemia de coronavírus <end>',\n",
       " '<start> Sobe para 20 o número de mortos por coronavírus no Hospital de Campanha do Anhembi em SP <end>',\n",
       " '<start> Itália tem menor número de mortos por Covid-19 desde o início de março <end>',\n",
       " '<start> Taxa de isolamento sobe para 50% no estado de SP no sábado; na capital paulista chega a 52% <end>',\n",
       " '<start> Quanto mais cedo, melhor? O debate sobre a idade certa, os métodos e a avaliação na alfabetização de crianças <end>',\n",
       " '<start> Justiça homologa acordos entre MP e frigoríficos para retomada das atividades em Lajeado <end>',\n",
       " '<start> Bolsonaro e pelo menos 11 ministros participam de ato pró-governo no Palácio do Planalto <end>',\n",
       " '<start> Índia prolonga confinamento pela Covid-19 até 31 de maio <end>',\n",
       " '<start> Justiça determina que PM fiscalize filas na Caixa para evitar aglomerações devido ao auxílio emergencial <end>',\n",
       " '<start> Bariri confirma primeira morte por Covid-19 <end>',\n",
       " '<start> Secretário de Saúde do RJ deixa o cargo durante a pandemia de Covid-19 <end>',\n",
       " '<start> Inauguração de Hospital de Campanha em São Gonçalo, dedicado ao combate à Covid-19, não é realizada  <end>',\n",
       " '<start> Flávio Bolsonaro foi avisado por delegado da PF de operação que deixaria Queiroz em evidência, diz ex-aliado <end>',\n",
       " '<start> Pacientes da Covid-19 ocupam 85% dos leitos de UTI do SUS no Rio <end>',\n",
       " '<start> Mortes por Covid-19 crescem 432% em um mês na cidade de SP e sistema de saúde pode colapsar em 15 dias, diz prefeitura <end>',\n",
       " '<start> Ludmilla recebe alta de hospital e seguirá tratando problema renal em casa <end>',\n",
       " '<start> Parlamento israelense realiza cerimônia de posse de governo de coalizão entre Netanyahu e Gantz <end>',\n",
       " '<start> Casos de coronavírus e número de mortes no Brasil em 17 de maio <end>',\n",
       " '<start> Bruno Covas anuncia retomada do rodízio de carros tradicional a partir desta segunda-feira <end>',\n",
       " '<start> Semana em SP começa com tempo encoberto e queda nas temperaturas  <end>',\n",
       " '<start> América Latina e Caribe passam de meio milhão de casos de coronavírus confirmados <end>',\n",
       " '<start> Exame de coronavírus do vice Hamilton Mourão tem resultado negativo, informa assessoria <end>',\n",
       " '<start> Coronavírus: Unicamp cria projeto preliminar para retomada gradual das atividades presenciais <end>',\n",
       " \"<start> João Paulo 2º: os cem anos do primeiro 'papa pop' <end>\",\n",
       " '<start> Agentes da Comlurb realizam trabalho de higienização em comunidades da Zona Oeste do Rio neste domingo <end>',\n",
       " '<start> Reservatório de Sobradinho beira a capacidade máxima no sertão da Bahia <end>',\n",
       " '<start> Coronavírus: as incertezas e os cuidados para pessoas com síndrome de Down <end>',\n",
       " '<start> Venda de orgânicos cresce na pandemia com produtores apostando em novas formas de negociação <end>',\n",
       " '<start> Produtor do RS transforma tradição familiar do vinagre de cana em negócio <end>',\n",
       " '<start> Queda nos preços prejudica produtores de mandioca do Paraná <end>',\n",
       " '<start> Embaixador da China em Israel é encontrado morto em casa <end>',\n",
       " '<start> Falta de chuvas atrapalha e segunda safra de milho em Goiás deverá ser menor <end>',\n",
       " '<start> Retirada da vacinação da febre aftosa no rebanho brasileiro pode atrasar por causa do coronavírus, diz ministério <end>',\n",
       " '<start> Aprenda a fazer uma criação de pirarucu  <end>',\n",
       " '<start> Pequenas Empresas & Grandes Negócios: contatos de 17/05/2020 <end>',\n",
       " '<start> Especialista dá dicas para fazer lives de sucesso na internet <end>',\n",
       " '<start> Empresas se reinventam para atender idosos que estão sozinhos em casa <end>',\n",
       " '<start> Totens fazem medição de temperatura automatizada de pacientes <end>',\n",
       " '<start> Startup organiza ajuda entre vizinhos durante pandemia <end>',\n",
       " '<start> Empreendedor produz pantufas customizadas durante isolamento social <end>',\n",
       " '<start> Startup oferece mercado de autoatendimento dentro de condomínios <end>',\n",
       " '<start> Contra a letargia, consciência e pertencimento <end>',\n",
       " '<start> Polícia do RJ prende homem considerado o braço direito do miliciano Ecko <end>',\n",
       " '<start> Últimas notícias de coronavírus de 17 de maio <end>',\n",
       " '<start> Doação de dinheiro do cofrinho, cartinhas, desenhos e fantasia: veja como crianças enfrentam a pandemia no Brasil e no mundo <end>',\n",
       " '<start> Nosso Campo exibe reprises de reportagens neste domingo, 17 de maio <end>',\n",
       " \"<start> Kell Smith encara vulnerabilidades no 'lado A' do álbum 'O velho e bom novo' <end>\",\n",
       " '<start> Orquestra Sinfônica de Santo André apresenta neste domingo músicas sobre o isolamento social  <end>',\n",
       " '<start> Covid-19: desigualdade demanda regulação única de leitos, diz especialista <end>',\n",
       " '<start> G1 Ouviu #89 - Babu Santana: turnê, parcerias e a vida do Paizão pós-BBB <end>',\n",
       " '<start> Babu Santana fala sobre planos pós-BBB e faz live com Thelma, Manu e Gabigol neste domingo <end>',\n",
       " \"<start> Sem 'maturidade', Melim faz o pop que se espera do trio no disco 'Eu feat. você' <end>\",\n",
       " \"<start> Coronavírus: 21 estados e o DF propõem projetos para multar quem divulga 'fake news' na pandemia <end>\",\n",
       " '<start> Globoplay esclarece que invasores apenas mandaram notificação pelo app; nenhum sistema foi invadido e não é necessário apagar o aplicativo <end>',\n",
       " \"<start> Momo anuncia para agosto o EP 'Sail your boat into my sea' <end>\",\n",
       " '<start> Lives de hoje: Wesley Safadão e Raça Negra, Diogo Nogueira, Babu Santana e mais transmissões <end>',\n",
       " \"<start> Discos para descobrir em casa – 'Tardes cariocas', Joyce Moreno, 1983 <end>\",\n",
       " '<start> Em debate, governadores pedem sanção de socorro aos estados <end>',\n",
       " '<start> Peru anuncia chegada de médicos cubanos para ajudar a combater a Covid-19 <end>',\n",
       " '<start> Rio e Niterói registram panelaços na noite deste sábado <end>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "GwlLqXmQC7aU",
    "outputId": "f3739a60-ec96-4628-e285-7dc5c5b5d45e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_lang.word_index['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SYDsPfw5mlqR"
   },
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "g88lLJYIdVFR",
    "outputId": "ff8f85d7-9aa3-4ee1-cea8-7161c4d67dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229 229 58 58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# faz separacao 80/20\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# mostra tamanhos\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lnvQHQXsm7u6",
    "outputId": "a7aa0faa-53ec-4180-c9b6-08ef26071f32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "42 ----> <start>\n",
      "26 ----> são\n",
      "20 ----> mais\n",
      "1 ----> de\n",
      "571 ----> 16\n",
      "81 ----> mil\n",
      "115 ----> mortes\n",
      "11 ----> no\n",
      "215 ----> brasil,\n",
      "32 ----> mas\n",
      "9 ----> para\n",
      "15 ----> uma\n",
      "11959 ----> minoria\n",
      "705 ----> parece\n",
      "5 ----> que\n",
      "317 ----> tanto\n",
      "11960 ----> faz.\n",
      "3 ----> o\n",
      "9123 ----> fantástico\n",
      "11961 ----> pergunta:\n",
      "18 ----> por\n",
      "5 ----> que\n",
      "16 ----> é\n",
      "5 ----> que\n",
      "38 ----> tem\n",
      "82 ----> gente\n",
      "5 ----> que\n",
      "9124 ----> age\n",
      "23 ----> como\n",
      "25 ----> se\n",
      "2 ----> a\n",
      "60 ----> pandemia\n",
      "17 ----> não\n",
      "3396 ----> estivesse\n",
      "11962 ----> acontecendo?\n",
      "11 ----> no\n",
      "61 ----> dia\n",
      "7 ----> em\n",
      "5 ----> que\n",
      "3 ----> o\n",
      "103 ----> brasil\n",
      "1203 ----> contou\n",
      "223 ----> 10\n",
      "81 ----> mil\n",
      "525 ----> mortos\n",
      "18 ----> por\n",
      "173 ----> coronavírus,\n",
      "13 ----> um\n",
      "1645 ----> cliente\n",
      "593 ----> pediu\n",
      "11963 ----> vinho\n",
      "11964 ----> espumante\n",
      "7 ----> em\n",
      "13 ----> um\n",
      "9125 ----> restaurante\n",
      "1 ----> de\n",
      "11965 ----> gramado,\n",
      "91 ----> rio\n",
      "118 ----> grande\n",
      "6 ----> do\n",
      "3072 ----> sul.\n",
      "19 ----> as\n",
      "11966 ----> garrafas\n",
      "54 ----> foram\n",
      "11967 ----> servidas\n",
      "7 ----> em\n",
      "11968 ----> caprichadas\n",
      "11969 ----> champanheiras.\n",
      "11970 ----> guiados\n",
      "18 ----> por\n",
      "13 ----> um\n",
      "11971 ----> cliente,\n",
      "11972 ----> garçons\n",
      "11973 ----> animados\n",
      "11974 ----> dançam\n",
      "15 ----> uma\n",
      "11975 ----> coreografia\n",
      "11976 ----> ensaiada.\n",
      "11977 ----> imitam\n",
      "3 ----> o\n",
      "11978 ----> meme\n",
      "6 ----> do\n",
      "11979 ----> caixão,\n",
      "15 ----> uma\n",
      "11980 ----> piada\n",
      "1 ----> de\n",
      "1615 ----> gosto\n",
      "11981 ----> duvidoso\n",
      "10 ----> com\n",
      "11982 ----> enterros\n",
      "11983 ----> africanos,\n",
      "32 ----> mas\n",
      "5 ----> que\n",
      "336 ----> muitos\n",
      "1763 ----> usam\n",
      "18 ----> por\n",
      "540 ----> aqui\n",
      "23 ----> como\n",
      "224 ----> forma\n",
      "1 ----> de\n",
      "4536 ----> alertar\n",
      "9 ----> para\n",
      "14 ----> os\n",
      "1813 ----> riscos\n",
      "8 ----> da\n",
      "209 ----> pandemia.\n",
      "88 ----> essa\n",
      "11984 ----> comemoração\n",
      "7 ----> em\n",
      "1405 ----> público,\n",
      "11985 ----> debochando\n",
      "8 ----> da\n",
      "272 ----> morte\n",
      "7 ----> em\n",
      "1487 ----> tempos\n",
      "1 ----> de\n",
      "192 ----> covid-19,\n",
      "11986 ----> chocou\n",
      "634 ----> muita\n",
      "5526 ----> gente.\n",
      "2 ----> a\n",
      "3678 ----> direção\n",
      "6 ----> do\n",
      "11987 ----> bar\n",
      "593 ----> pediu\n",
      "9126 ----> desculpas.\n",
      "7 ----> em\n",
      "11988 ----> araucária,\n",
      "1328 ----> perto\n",
      "1 ----> de\n",
      "9127 ----> curitiba,\n",
      "3 ----> o\n",
      "274 ----> empresário\n",
      "9128 ----> danir\n",
      "11989 ----> garbossa,\n",
      "9129 ----> insiste\n",
      "7 ----> em\n",
      "528 ----> entrar\n",
      "11 ----> no\n",
      "2296 ----> supermercado\n",
      "69 ----> sem\n",
      "504 ----> usar\n",
      "1727 ----> máscara,\n",
      "4371 ----> obrigatória\n",
      "12 ----> na\n",
      "325 ----> cidade.\n",
      "40 ----> ele\n",
      "11990 ----> agride\n",
      "13 ----> um\n",
      "1243 ----> funcionário\n",
      "4 ----> e\n",
      "11991 ----> arruma\n",
      "9103 ----> confusão\n",
      "10 ----> com\n",
      "3 ----> o\n",
      "4098 ----> segurança.\n",
      "2 ----> a\n",
      "9110 ----> arma\n",
      "6 ----> do\n",
      "11992 ----> vigia\n",
      "11993 ----> dispara\n",
      "219 ----> duas\n",
      "5793 ----> vezes.\n",
      "15 ----> uma\n",
      "9130 ----> bala\n",
      "11994 ----> atinge\n",
      "3 ----> o\n",
      "274 ----> empresário\n",
      "1 ----> de\n",
      "11995 ----> raspão.\n",
      "2 ----> a\n",
      "237 ----> outra\n",
      "1453 ----> acaba\n",
      "11 ----> no\n",
      "11996 ----> pescoço\n",
      "8 ----> da\n",
      "9131 ----> funcionária\n",
      "11997 ----> sandra\n",
      "5188 ----> ribeiro,\n",
      "1 ----> de\n",
      "1507 ----> 45\n",
      "446 ----> anos.\n",
      "75 ----> ela\n",
      "11998 ----> morreu.\n",
      "9128 ----> danir\n",
      "85 ----> vai\n",
      "1348 ----> responder\n",
      "18 ----> por\n",
      "159 ----> três\n",
      "9132 ----> acusações,\n",
      "1646 ----> incluindo\n",
      "3 ----> o\n",
      "4539 ----> homicídio\n",
      "11999 ----> qualificado\n",
      "1 ----> de\n",
      "12000 ----> sandra.\n",
      "18 ----> por\n",
      "5 ----> que\n",
      "38 ----> tem\n",
      "82 ----> gente\n",
      "5 ----> que\n",
      "17 ----> não\n",
      "889 ----> consegue\n",
      "2359 ----> exercer\n",
      "2 ----> a\n",
      "9133 ----> empatia\n",
      "7 ----> em\n",
      "5794 ----> plena\n",
      "5795 ----> pandemia?\n",
      "2 ----> a\n",
      "12001 ----> neurocientista\n",
      "9134 ----> cláudia\n",
      "12002 ----> feitosa-santana\n",
      "3032 ----> acha\n",
      "5 ----> que\n",
      "9135 ----> negar\n",
      "2 ----> a\n",
      "1080 ----> gravidade\n",
      "8 ----> da\n",
      "222 ----> doença\n",
      "106 ----> pode\n",
      "41 ----> ser\n",
      "15 ----> uma\n",
      "538 ----> defesa\n",
      "3310 ----> encontrada\n",
      "18 ----> por\n",
      "242 ----> algumas\n",
      "45 ----> pessoas\n",
      "5 ----> que\n",
      "17 ----> não\n",
      "9136 ----> conseguem\n",
      "9137 ----> encarar\n",
      "3 ----> o\n",
      "2086 ----> peso\n",
      "8 ----> da\n",
      "5796 ----> pandemia:\n",
      "2595 ----> “em\n",
      "709 ----> geral\n",
      "57 ----> nos\n",
      "2404 ----> seres\n",
      "1498 ----> humanos\n",
      "3 ----> o\n",
      "5 ----> que\n",
      "1159 ----> acontece\n",
      "10 ----> com\n",
      "2 ----> a\n",
      "12003 ----> gente?\n",
      "59 ----> quando\n",
      "863 ----> vem\n",
      "15 ----> uma\n",
      "2165 ----> dificuldade\n",
      "62 ----> muito\n",
      "2567 ----> grande,\n",
      "34 ----> ou\n",
      "3 ----> o\n",
      "4540 ----> anúncio\n",
      "8 ----> da\n",
      "272 ----> morte\n",
      "1 ----> de\n",
      "1299 ----> alguém\n",
      "5 ----> que\n",
      "12004 ----> morre\n",
      "62 ----> muito\n",
      "12005 ----> querido,\n",
      "354 ----> qual\n",
      "16 ----> é\n",
      "281 ----> nossa\n",
      "164 ----> primeira\n",
      "12006 ----> reação?\n",
      "16 ----> é\n",
      "12007 ----> negar,\n",
      "74 ----> isso\n",
      "17 ----> não\n",
      "16 ----> é\n",
      "12008 ----> verdade”.\n",
      "2 ----> a\n",
      "12009 ----> empatia,\n",
      "4541 ----> sozinha,\n",
      "106 ----> pode\n",
      "17 ----> não\n",
      "3679 ----> resolver\n",
      "1442 ----> nossos\n",
      "9138 ----> problemas.\n",
      "32 ----> mas\n",
      "5790 ----> andar\n",
      "10 ----> com\n",
      "14 ----> os\n",
      "12010 ----> sapatos\n",
      "12011 ----> alheios,\n",
      "25 ----> se\n",
      "1806 ----> colocar\n",
      "11 ----> no\n",
      "606 ----> lugar\n",
      "6 ----> do\n",
      "4300 ----> outro,\n",
      "1938 ----> buscar\n",
      "3 ----> o\n",
      "12012 ----> diálogo,\n",
      "221 ----> tudo\n",
      "74 ----> isso\n",
      "106 ----> pode\n",
      "2622 ----> reforçar\n",
      "5797 ----> aquilo\n",
      "5 ----> que\n",
      "2 ----> a\n",
      "4542 ----> emergência,\n",
      "2 ----> a\n",
      "1584 ----> ameaça\n",
      "4 ----> e\n",
      "2 ----> a\n",
      "263 ----> falta\n",
      "1 ----> de\n",
      "2452 ----> cuidado\n",
      "10 ----> com\n",
      "14 ----> os\n",
      "161 ----> outros\n",
      "1873 ----> tenta\n",
      "12013 ----> eliminar:\n",
      "2 ----> a\n",
      "281 ----> nossa\n",
      "12014 ----> humanidade.\n",
      "208 ----> veja\n",
      "33 ----> também\n",
      "1643 ----> \"foi\n",
      "15 ----> uma\n",
      "195 ----> relação\n",
      "4543 ----> baseada\n",
      "7 ----> em\n",
      "62 ----> muito\n",
      "3573 ----> amor\",\n",
      "3680 ----> revela\n",
      "921 ----> suposto\n",
      "4544 ----> companheiro\n",
      "1 ----> de\n",
      "5798 ----> gugu\n",
      "43 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "12 ----> por\n",
      "11 ----> que\n",
      "37 ----> tem\n",
      "319 ----> gente\n",
      "11 ----> que\n",
      "554 ----> age\n",
      "90 ----> como\n",
      "31 ----> se\n",
      "32 ----> não\n",
      "555 ----> houvesse\n",
      "9 ----> a\n",
      "556 ----> pandemia?\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nj1kuh2hirSd"
   },
   "outputs": [],
   "source": [
    "# criando o dataset\n",
    "\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 16\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 200\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VUSjdb22jMoU",
    "outputId": "13d72eac-e8f1-4290-d188-9cea435992d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([16, 600]), TensorShape([16, 20]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hc8hA8NNjSuc"
   },
   "outputs": [],
   "source": [
    "# bloco do encoder\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "fmvm1TGQjUGz",
    "outputId": "e01c201d-eaf7-4ccd-e72f-96d2ffb14ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (16, 600, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (16, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "s61ZzdrjjaqT"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "3bDQHCeUjdeb",
    "outputId": "1aee5ebe-a5b4-4f7f-ce89-031a0a8ec46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (16, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (16, 600, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "f3vSHrnojjE7"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "    print(context_vector)\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "    print(x)\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "nSZVg3F7jk5T",
    "outputId": "a33c5576-1010-4308-bc2e-38eff0219f1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.00314646  0.00860887  0.00222098 ...  0.00997951  0.00246175\n",
      "  -0.00527798]\n",
      " [-0.00207971  0.00589338  0.00118219 ...  0.00599809  0.00191839\n",
      "  -0.00283943]\n",
      " [-0.00297884  0.00742073  0.00155249 ...  0.00870708  0.00184641\n",
      "  -0.00463275]\n",
      " ...\n",
      " [-0.00241177  0.00423362 -0.00014944 ...  0.00373702  0.00081356\n",
      "  -0.00189337]\n",
      " [-0.00204971  0.00039885 -0.00046536 ... -0.00048837 -0.00015328\n",
      "  -0.00069056]\n",
      " [-0.00143831  0.00043566 -0.00035437 ... -0.00093647  0.00026161\n",
      "  -0.00113795]], shape=(16, 1024), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-0.01127663 -0.0161803   0.00200553 ...  0.03489823 -0.04394979\n",
      "   -0.03381564]]\n",
      "\n",
      " [[-0.01127663 -0.0161803   0.00200553 ...  0.03489823 -0.04394979\n",
      "   -0.03381564]]\n",
      "\n",
      " [[-0.01127663 -0.0161803   0.00200553 ...  0.03489823 -0.04394979\n",
      "   -0.03381564]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.01127663 -0.0161803   0.00200553 ...  0.03489823 -0.04394979\n",
      "   -0.03381564]]\n",
      "\n",
      " [[-0.01127663 -0.0161803   0.00200553 ...  0.03489823 -0.04394979\n",
      "   -0.03381564]]\n",
      "\n",
      " [[-0.01127663 -0.0161803   0.00200553 ...  0.03489823 -0.04394979\n",
      "   -0.03381564]]], shape=(16, 1, 200), dtype=float32)\n",
      "Decoder output shape: (batch_size, vocab size) (16, 1612)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "48arRwVYjqIL"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tQriFWRIjryT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ccxVaiRLj51C"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(targ_lang.word_index['<start>'])\n",
    "print([targ_lang.word_index['<start>']] * BATCH_SIZE)\n",
    "print(targ_lang.word_index['<start>'] * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JV-hYcnOkBOa",
    "outputId": "f8820948-c8cd-4c3f-f36a-26c6730584bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"decoder_1/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_1/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_1/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_2/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_2/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_3/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_3/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_4/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_4/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_5/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_5/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_6/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_6/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_7/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_7/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_8/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_8/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_9/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_9/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_10/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_10/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_11/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_11/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_12/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_12/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_13/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_13/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_14/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_14/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_15/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_15/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_16/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_16/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_17/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_17/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_18/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_18/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_1/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_1/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_2/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_2/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_3/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_3/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_4/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_4/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_5/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_5/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_6/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_6/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_7/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_7/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_8/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_8/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_9/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_9/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_10/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_10/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_11/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_11/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_12/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_12/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_13/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_13/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_14/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_14/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_15/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_15/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_16/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_16/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_17/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_17/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n",
      "Tensor(\"decoder_1_18/bahdanau_attention_2/Sum:0\", shape=(16, 1024), dtype=float32)\n",
      "Tensor(\"decoder_1_18/embedding_2/embedding_lookup/Identity_1:0\", shape=(16, 1, 200), dtype=float32)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[16,600,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Mul_183 (defined at <ipython-input-27-49d4266c745b>:26) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[concat_19/_212]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[16,600,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Mul_183 (defined at <ipython-input-27-49d4266c745b>:26) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_39260]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Mul_183:\n decoder_1_1/bahdanau_attention_2/transpose_1 (defined at <ipython-input-13-1d1a7c0866b1>:22)\n\nInput Source operations connected to node Mul_183:\n decoder_1_1/bahdanau_attention_2/transpose_1 (defined at <ipython-input-13-1d1a7c0866b1>:22)\n\nFunction call stack:\ntrain_step -> train_step\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-7b03f9d4b439>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[16,600,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Mul_183 (defined at <ipython-input-27-49d4266c745b>:26) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[concat_19/_212]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[16,600,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Mul_183 (defined at <ipython-input-27-49d4266c745b>:26) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_39260]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Mul_183:\n decoder_1_1/bahdanau_attention_2/transpose_1 (defined at <ipython-input-13-1d1a7c0866b1>:22)\n\nInput Source operations connected to node Mul_183:\n decoder_1_1/bahdanau_attention_2/transpose_1 (defined at <ipython-input-13-1d1a7c0866b1>:22)\n\nFunction call stack:\ntrain_step -> train_step\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "loss_acumulado = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  loss_acumulado.append(total_loss / steps_per_epoch)\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "ZAM9TMv8ND4f",
    "outputId": "fd0e80bb-e744-4aca-e01f-a6c32d86c9e2"
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_acumulado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZXcFnrz984X"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = sentence.lower()\n",
    "\n",
    "  inputs = inp_lang.texts_to_sequences([sentence])\n",
    "\n",
    "  #inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "\n",
    "  print(inputs)\n",
    "\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  print(inputs.shape)\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "  print(inputs.shape)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot\n",
    "\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "cfJgm7-b-hx6",
    "outputId": "d8d927fa-4666-43ae-fdd8-9d87f17b8549"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "mensagem = '<start> ' + data.texto.tolist()[15] + ' <end>'\n",
    "print(mensagem)\n",
    "\n",
    "translate(mensagem)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sumarização Abstrata.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
