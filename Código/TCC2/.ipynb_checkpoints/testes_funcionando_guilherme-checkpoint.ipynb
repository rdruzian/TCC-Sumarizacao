{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiYHicaok-55",
    "outputId": "7f820bdc-f590-41a8-e697-c050cfec2e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from google.colab import drive\n",
    "drive.mount('/content/drive')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cCiShuJ2kJ46",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "C_WZdfH3vuAq"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1O-ULTskJ5D"
   },
   "source": [
    "# ETAPA DE CARREGAMENTO DO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SmMT4yLYkJ5E"
   },
   "outputs": [],
   "source": [
    "'''data = pd.read_json('/content/drive/My Drive/Colab Notebooks/tcc1.json', encoding='utf-8')'''\n",
    "data = pd.read_json('tcc1.json', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tgCi_w7kJ5H"
   },
   "source": [
    "# ETAPA DE PRÉ-PROCESSAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g0NmdK92kJ5H"
   },
   "outputs": [],
   "source": [
    "titulo_input = ['<start> ' + m + ' <end>' for m in data.título.tolist()]\n",
    "noticia_input = ['<start> ' + m + ' <end>' for m in data.texto.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX94W2FjkJ5K"
   },
   "source": [
    "# ETAPA DE TOKENIZAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R25m_iFJkJ5L"
   },
   "outputs": [],
   "source": [
    "def token(texto, tam_max):\n",
    "    tokens = tf.keras.preprocessing.text.Tokenizer(lower=True, filters='', num_words=2**16)\n",
    "    tokens.fit_on_texts(texto)\n",
    "    tensor = tokens.texts_to_sequences(texto)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=tam_max)\n",
    "    return tensor, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZMQ1BxRvkJ5N"
   },
   "outputs": [],
   "source": [
    "data_input_tokens, data_input = token(noticia_input, tam_max=600)\n",
    "data_target_tokens, target_input = token(titulo_input, tam_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GxtQBzu4kJ5Q"
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = data_input_tokens.shape[1]\n",
    "num_decoder_tokens = data_target_tokens.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQPcETPJkJ5T"
   },
   "source": [
    "# Divisão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rd9Tw4V5kJ5U",
    "outputId": "6654378e-1474-46f6-f549-f87709fb8b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229 58 229 58\n"
     ]
    }
   ],
   "source": [
    "input_data_train, input_data_test, input_decoder_train, input_decoder_test = train_test_split(data_input_tokens, data_target_tokens, test_size=0.2)\n",
    "\n",
    "print(len(input_data_train), len(input_data_test), len(input_decoder_train), len(input_decoder_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1ihsvoJkJ5X"
   },
   "source": [
    "# Variáveis de configuração da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ksAX-lLEkJ5X"
   },
   "outputs": [],
   "source": [
    "buffer = len(input_data_train)\n",
    "batch = 16\n",
    "steps_por_epoca = len(input_data_train)//batch\n",
    "embedding_dim = 200\n",
    "units = 1024\n",
    "vocab_size_input = len(data_input.word_index)+1\n",
    "vocab_size_target = len(target_input.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_data_train, input_decoder_train)).shuffle(buffer)\n",
    "dataset = dataset.batch(batch, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dm3nCdlIkJ5a",
    "outputId": "81280187-41e0-4aeb-b8e3-575e30c3ab14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([16, 600]), TensorShape([16, 20]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vHyxrLEkJ5d"
   },
   "source": [
    "# Criação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TCL3gnz7kJ5d",
    "outputId": "f8e458a4-b9e1-48fb-c194-5193efbe1383"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"encoder_input_data = np.zeros(\\n    (len(noticia_input), num_encoder_tokens, vocab_size_input), dtype='float32')\\ndecoder_input_data = np.zeros(\\n    (len(noticia_input), num_decoder_tokens, vocab_size_target), dtype='float32')\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''encoder_input_data = np.zeros(\n",
    "    (len(noticia_input), num_encoder_tokens, vocab_size_input), dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(noticia_input), num_decoder_tokens, vocab_size_target), dtype='float32')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "On0BMYHYkJ5g"
   },
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "W_BQGxePkJ5h",
    "outputId": "b62d50ab-db4e-4ebf-ad67-72733eb25baa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i, input_text in enumerate(input_data_train):\\n    for t, char in enumerate(input_text):\\n        encoder_input_data[i, t, char] = 1.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i, input_text in enumerate(input_data_train):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, char] = 1.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "iRHHLANekJ5j",
    "outputId": "62fe9c3e-79cd-4739-fcec-8101c7be680e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i, decoder_text in enumerate(input_decoder_train):\\n    for t, char in enumerate(decoder_text):\\n        decoder_input_data[i, t, char] = 1.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i, decoder_text in enumerate(input_decoder_train):\n",
    "    for t, char in enumerate(decoder_text):\n",
    "        decoder_input_data[i, t, char] = 1.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lILhlbnSkJ5m"
   },
   "source": [
    "# Arquitetura da Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ifBysSYHkJ5m"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, emb_dim, units, batch):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch = batch\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        #print(\"x encoder: \", x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        print(\"output encoder: \", output)\n",
    "        print(\"output state: \", state)\n",
    "        return output, state\n",
    "    \n",
    "    def intializer_hidden_state(self):\n",
    "        return tf.zeros((self.batch, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCNz48DMkJ5p",
    "outputId": "e72dff37-903c-468b-b5b6-15acdd5f257a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output encoder:  tf.Tensor(\n",
      "[[[-3.0842243e-04 -6.5526515e-03  3.9992554e-04 ... -3.7998706e-03\n",
      "    7.3350510e-03 -5.1927976e-03]\n",
      "  [-2.9863871e-03 -3.4470323e-03  4.0791119e-03 ... -1.6927108e-03\n",
      "    8.5208064e-04 -5.6904852e-03]\n",
      "  [-1.0755990e-02  6.7602685e-03  2.5231366e-03 ...  8.5079940e-03\n",
      "   -3.3086690e-05  6.5111695e-03]\n",
      "  ...\n",
      "  [ 2.6263280e-03  1.5370127e-02 -3.4013853e-04 ... -6.9554704e-03\n",
      "    2.3309011e-03  1.0773129e-02]\n",
      "  [ 4.5271707e-03  1.4697173e-02 -4.8892382e-03 ... -1.3122638e-02\n",
      "   -5.5989535e-03  1.3821453e-02]\n",
      "  [ 8.9046033e-03  2.0129342e-02 -7.3118485e-03 ... -5.8914698e-03\n",
      "    3.4166005e-04  8.8573210e-03]]\n",
      "\n",
      " [[-5.4864842e-03  3.2015759e-03  6.2299026e-03 ...  8.0112839e-04\n",
      "    5.3224829e-03  7.2475045e-04]\n",
      "  [-1.4812694e-02 -4.0351022e-03 -1.2637429e-03 ...  4.3218979e-03\n",
      "   -1.0250750e-03 -2.0387364e-03]\n",
      "  [-9.0720020e-03 -8.4501067e-03 -3.5780377e-03 ... -3.5325003e-05\n",
      "    1.6717615e-03 -1.1555740e-03]\n",
      "  ...\n",
      "  [ 4.9049803e-03  4.4716438e-03  5.1473258e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049803e-03  4.4716438e-03  5.1473258e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049803e-03  4.4716438e-03  5.1473258e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]]\n",
      "\n",
      " [[-5.4864842e-03  3.2015759e-03  6.2299026e-03 ...  8.0112839e-04\n",
      "    5.3224829e-03  7.2475045e-04]\n",
      "  [-3.9494238e-03 -2.9451197e-03  2.8962451e-03 ... -4.8452962e-04\n",
      "    1.1492824e-02  4.9152666e-05]\n",
      "  [-1.0837253e-02 -1.5480552e-04  2.7829648e-03 ...  1.5533317e-03\n",
      "    4.3471227e-03  1.8810140e-03]\n",
      "  ...\n",
      "  [ 4.9049798e-03  4.4716438e-03  5.1473258e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049798e-03  4.4716438e-03  5.1473258e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049798e-03  4.4716438e-03  5.1473258e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-5.4864842e-03  3.2015759e-03  6.2299026e-03 ...  8.0112839e-04\n",
      "    5.3224829e-03  7.2475045e-04]\n",
      "  [-7.9713427e-03  1.1034697e-02  7.1941512e-03 ...  7.6864446e-03\n",
      "    6.8061780e-03 -3.8800991e-04]\n",
      "  [-1.1500001e-02  4.5684096e-03  9.1291312e-03 ...  1.0848791e-02\n",
      "    4.9885670e-03 -2.5329774e-03]\n",
      "  ...\n",
      "  [ 4.9049794e-03  4.4716443e-03  5.1473263e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049794e-03  4.4716443e-03  5.1473263e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049794e-03  4.4716443e-03  5.1473263e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]]\n",
      "\n",
      " [[-5.4864842e-03  3.2015759e-03  6.2299026e-03 ...  8.0112839e-04\n",
      "    5.3224829e-03  7.2475045e-04]\n",
      "  [-1.4812694e-02 -4.0351022e-03 -1.2637429e-03 ...  4.3218979e-03\n",
      "   -1.0250750e-03 -2.0387364e-03]\n",
      "  [ 1.4638335e-03 -1.3201046e-02 -5.2586789e-03 ... -9.1124594e-04\n",
      "    2.5867471e-03  1.1384630e-03]\n",
      "  ...\n",
      "  [ 4.9049803e-03  4.4716443e-03  5.1473258e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049803e-03  4.4716443e-03  5.1473258e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049803e-03  4.4716443e-03  5.1473258e-03 ...  8.7063881e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]]\n",
      "\n",
      " [[-5.4864842e-03  3.2015759e-03  6.2299026e-03 ...  8.0112839e-04\n",
      "    5.3224829e-03  7.2475045e-04]\n",
      "  [-7.2872513e-03  8.4615154e-03  5.7787276e-03 ...  5.0130128e-03\n",
      "    1.8298830e-03  9.5939925e-03]\n",
      "  [-2.0420786e-03  9.8726563e-03 -1.4849944e-03 ... -4.1642333e-03\n",
      "    6.6952361e-03 -2.7445005e-04]\n",
      "  ...\n",
      "  [ 4.9049798e-03  4.4716438e-03  5.1473263e-03 ...  8.7063890e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049798e-03  4.4716438e-03  5.1473263e-03 ...  8.7063890e-03\n",
      "   -4.6724696e-03 -1.8515188e-02]\n",
      "  [ 4.9049798e-03  4.4716438e-03  5.1473263e-03 ...  8.7063890e-03\n",
      "   -4.6724691e-03 -1.8515188e-02]]], shape=(16, 600, 1024), dtype=float32)\n",
      "output state:  tf.Tensor(\n",
      "[[ 0.0089046   0.02012934 -0.00731185 ... -0.00589147  0.00034166\n",
      "   0.00885732]\n",
      " [ 0.00490498  0.00447164  0.00514733 ...  0.00870639 -0.00467247\n",
      "  -0.01851519]\n",
      " [ 0.00490498  0.00447164  0.00514733 ...  0.00870639 -0.00467247\n",
      "  -0.01851519]\n",
      " ...\n",
      " [ 0.00490498  0.00447164  0.00514733 ...  0.00870639 -0.00467247\n",
      "  -0.01851519]\n",
      " [ 0.00490498  0.00447164  0.00514733 ...  0.00870639 -0.00467247\n",
      "  -0.01851519]\n",
      " [ 0.00490498  0.00447164  0.00514733 ...  0.00870639 -0.00467247\n",
      "  -0.01851519]], shape=(16, 1024), dtype=float32)\n",
      "Encoder output shape: (batch size, sequence length, units) (16, 600, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (16, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size_input, embedding_dim, units, batch)\n",
    "\n",
    "sample_hidden = encoder.intializer_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "asNtvs7zkJ5u"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rkEZu7eKkJ51"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, emb_dim, units, batch):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch = batch\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.units)\n",
    "\n",
    "    def call(self, x, hidden, output):\n",
    "        context_vector, attention_weights = self.attention(hidden, output)\n",
    "        x = self.embedding(x)\n",
    "        #print(x)\n",
    "        #print([tf.expand_dims(context_vector, 1), x])\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        return output, state, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRo90eCfkJ53",
    "outputId": "bc1170ba-a6a0-4c57-ef78-8e7e33d2494c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (16, 1024)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size_target, embedding_dim, units, batch)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((batch, 1)), sample_hidden, sample_output)\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zeZxJIh_kJ56"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "def erro(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6crPZGaLkJ58"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './treinamento_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=tf.keras.optimizers.Adam(), encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mQxRP3edkJ5_"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def treino(input_data, target, hidden):\n",
    "    loss = 0\n",
    "    batch = 16\n",
    "    #print(input_data)\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_output, encoder_hidden = encoder(input_data, hidden)\n",
    "        decoder_input = tf.expand_dims([target_input.word_index['<start>']] * batch, 1)\n",
    "\n",
    "        for t in range(1, target.shape[1]):\n",
    "            predictions, decoder_hidden, _ = decoder(decoder_input, encoder_hidden, encoder_output)\n",
    "            loss += erro(target[:, t], predictions)\n",
    "            # using teacher forcing\n",
    "            decoder_input = tf.expand_dims(target[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(target.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "48MGJZS_kJ6C",
    "outputId": "965a6873-bd2a-4933-b009-da2618f53b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output encoder:  Tensor(\"encoder/gru/StatefulPartitionedCall:1\", shape=(16, 600, 1024), dtype=float32)\n",
      "output state:  Tensor(\"encoder/gru/StatefulPartitionedCall:2\", shape=(16, 1024), dtype=float32)\n",
      "output encoder:  Tensor(\"encoder/gru/StatefulPartitionedCall:1\", shape=(16, 600, 1024), dtype=float32)\n",
      "output state:  Tensor(\"encoder/gru/StatefulPartitionedCall:2\", shape=(16, 1024), dtype=float32)\n",
      "Epoca 11 Erro nan\n",
      "Para uma época levou 38.115665435791016s\n",
      "Epoca 11 Erro nan\n",
      "Para uma época levou 8.964566707611084s\n",
      "Epoca 11 Erro nan\n",
      "Para uma época levou 9.022577285766602s\n",
      "Epoca 11 Erro nan\n",
      "Para uma época levou 8.9580659866333s\n"
     ]
    }
   ],
   "source": [
    "epocas = 10\n",
    "erro_acumulado = []\n",
    "for e in range(epocas):\n",
    "    inicio = time.time()\n",
    "    hidden = encoder.intializer_hidden_state()\n",
    "    erro_total = 0\n",
    "    for (batch, (input_data, target)) in enumerate(dataset.take(steps_por_epoca)):\n",
    "        batch_loss = treino(input_data, target, hidden)\n",
    "        erro_total += batch_loss\n",
    "        \n",
    "    print('Epoca {} Erro {:.04f}'.format(epocas+1, erro_total/steps_por_epoca))\n",
    "    erro_acumulado.append(erro_total/steps_por_epoca)\n",
    "    print('Para uma época levou {}s'.format(time.time() - inicio))\n",
    "checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "ogXHVeFTkJ6F",
    "outputId": "853584b2-4fa6-4848-8c7e-20c797e98e96"
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkTT2pV5kJ6I",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lzFyp5FkJ6K"
   },
   "source": [
    "# Compilação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Itj6m-gkJ6L"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQyazX-QkJ6N"
   },
   "source": [
    "# Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgqGqWfckJ6O"
   },
   "outputs": [],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_input_data, batch_size=batch, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zVjRIzjkJ6Q"
   },
   "outputs": [],
   "source": [
    "model.save('sumAbstrat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-l-dA2oSvGmY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "testes_funcionando.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
